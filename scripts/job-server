#!/usr/bin/python
#
# Copyright (c) 2004-2006 rPath, Inc.
#
# All Rights Reserved
#

import errno
import re
import signal
import socket
import sys
import os
import random
import time
import threading
import traceback

from xmlrpclib import ProtocolError
from optparse import OptionParser

from conary import conaryclient
from conary.conarycfg import ConfigFile, ConaryConfiguration
from conary.conarycfg import CfgList, CfgString, CfgBool, CfgInt
from conary.deps import deps
from conary.lib import log, util

# to run from CVS
sys.path.append('..')

from mint.mint import MintClient
from mint import jobs
from mint import jobstatus
from mint import releasetypes

# image generators
from mint.distro.installable_iso import InstallableIso
from mint.distro.live_iso import LiveIso
from mint.distro.live_cf_image import LiveCFImage
from mint.distro.stub_image import StubImage
from mint.distro.netboot_image import NetbootImage
from mint.distro.group_trove import GroupTroveCook
from mint.distro.bootable_image import BootableImage

generators = {
    releasetypes.INSTALLABLE_ISO:   InstallableIso,
    releasetypes.STUB_IMAGE:        StubImage,
}

SUPPORTED_ARCHS = ('x86', 'x86_64')

class JobRunner(threading.Thread):
    def __init__(self, cfg, client, job):
        threading.Thread.__init__(self)
        self.cfg = cfg
        self.client = client
        self.job = job
        # still in parent thread when init gets called.
        self.parentThread = threading.currentThread()

    def run(self):
        # ensure each job thread has it's own process space
        pid = os.fork()
        if not pid:
            self.doWork()
        else:
            try:
                os.waitpid(pid, 0)
            except OSError, e:
                if e.errno != 10:
                    raise

    def doWork(self):
        ret = None
        error = None
        jobId = self.job.getId()
        self.job.setStatus(jobstatus.RUNNING, 'Running')

        if self.job.releaseId:
            release = self.client.getRelease(self.job.releaseId)
            project = self.client.getProject(release.getProjectId())

            # save the current working directory in case the generator
            # (or scripts that change the wd)
            cwd = os.getcwd()
            try:
                #Iterate through the different jobs
                imageTypes = release.getImageTypes()
                imageFilenames = []
                if releasetypes.INSTALLABLE_ISO in imageTypes:
                    generator = generators[releasetypes.INSTALLABLE_ISO]
                    log.info("%s job for %s started (id %d)" % \
                             (generator.__name__,
                              project.getHostname(), jobId))
                    imageFilenames.extend(generator(self.client,
                                                    self.cfg, self.job,
                                                    release, project).write())
                    os.chdir(cwd)
                #Now for the bootable images
                imagegen = BootableImage(self.client, self.cfg, self.job, release, project)
                imagegen.setImageTypes(imageTypes)
                if imagegen.workToDo():
                    log.info("%s job for %s started (id %d)" % \
                             (BootableImage.__name__,
                              project.getHostname(), jobId))

                    imageFilenames.extend(imagegen.write())
                else:
                    log.info("job %s:%d did not have a bootable image"
                             " generation request" % (project.getHostname(),
                                                      jobId))

            except Exception, e:
                traceback.print_exc()
                sys.stdout.flush()
                error = e
                self.job.setStatus(jobstatus.ERROR, str(e))
            else:
                release.setFiles(imageFilenames)
                log.info("job %d finished: %s", jobId, str(imageFilenames))
            os.chdir(cwd)
        elif self.job.getGroupTroveId():
            try:
                log.info("GroupTroveCook job started (id %d)" % (jobId))
                ret = GroupTroveCook(self.client, self.cfg, self.job,
                                     None).write()
            except Exception, e:
                traceback.print_exc()
                sys.stdout.flush()
                error = e
                self.job.setStatus(jobstatus.ERROR, str(e))
            else:
                log.info("job %d succeeded: %s" % (jobId, str(ret)))

        if error:
            log.info(error)
        else:
            self.job.setStatus(jobstatus.FINISHED, "Finished")

def updateWaitStatus(client):
    joblist = client.getJobs()
    for job in joblist:
        if job.getStatus() == jobstatus.WAITING:
            job.setStatus(jobstatus.WAITING,
                          client.server.getJobWaitMessage(job.getId()))

class JobDaemon:
    def __init__(self, cfg):
        client = MintClient(cfg.serverUrl)

        confirmedAlive = False

        try:
            os.makedirs(cfg.logPath)
        except OSError, e:
            if e.errno != errno.EEXIST:
                raise

        # normalize the job daemon machine's architecture
        # right now we only handle x86 and x86_64 images
        log.info("handling jobs of architecture: %s", cfg.supportedArch)

        runningJobs = []

        while(True):
            for jobThread in runningJobs[:]:
                if not jobThread.isAlive():
                    jobThread.join()
                    runningJobs.remove(jobThread)

            if len(runningJobs) < cfg.maxThreads:
                try:
                    job = client.startNextJob(["1#" + x for x in \
                                               cfg.supportedArch])
                    confirmedAlive = True

                    if not job:
                        # sleeping for a random interval helps prevent
                        # concurrency issues with multiple instances of
                        # this code
                        time.sleep(random.uniform(3, 5))
                        continue

                    if job.releaseId:
                        release = client.getRelease(job.releaseId)
                        if release.getArch() not in cfg.supportedArch:
                            continue

                    job.setStatus(jobstatus.RUNNING, 'Starting')
                    th = JobRunner(cfg, client, job)
                    th.start()
                    updateWaitStatus(client)

                    # queue this thread and move on
                    runningJobs.append(th)

                # if the rBuilder Online server is down, we will get either a
                # ProtocolError or a socket error depending on what xmlrpc lib
                # was doing when the server went down. simply wait for it.
                except (ProtocolError, socket.error), e:
                    if not confirmedAlive:
                        log.error("rBuilder Server Unreachable; exiting")
                        return
                    log.warning("Error retrieving job list:" + str(e))
                    time.sleep(5)
            else:
                # we get here if we already have (maxThreads) jobs running
                time.sleep(5)

def kill(lockFile):
    try:
        lock = open(lockFile, "r")
        pid = int(lock.read())
        lock.close()
    except Exception, e:
        log.warning("unable to open lockfile: %s (%s)", lockFile, str(e))
    else:
        pipeFD = os.popen("ps -p %d -o comm=" %pid)
        procName = pipeFD.readline().strip()
        pipeFD.close()
        if procName not in sys.argv[0]:
            log.error("pid: %d does not seem to be an rBuilder"
            " ISO generation server.")
            sys.exit(1)
        log.info("killing rBuilder ISO generation server pid %d" % pid)
        try:
            pass
            os.kill(pid, signal.SIGINT)
        except OSError, e:
            if e.errno != errno.ESRCH:
                raise
            else:
                log.info("process not found; removing lock file")
                os.unlink(lockFile)
        else:
            try:
                os.unlink(lockFile)
            except OSError, e:
                pass

def daemon(options, cfg):
    try:
        lock = open(cfg.lockFile, "w")
        lock.write("%d" % os.getpid())
        lock.close()
    except Exception, e:
        log.warning("unable to open lockfile: %s (%s)", cfg.lockFile, str(e))
    try:
        jd = JobDaemon(cfg)
    except socket.error, msg:
        log.error("connecting to rBuilder server: %s", msg[1])
    except KeyboardInterrupt:
        log.info("interrupt caught; exiting")

    try:
        os.unlink(cfg.lockFile)
    except (IOError, OSError):
        log.warning("unable to remove lockfile: %s", cfg.lockFile)

class IsoGenConfig(ConfigFile):
    supportedArch   = CfgList(CfgString)
    serverUrl       = None
    SSL             = (CfgBool, False)
    logPath         = '/srv/mint/logs'
    imagesPath      = '/srv/mint/images/'
    finishedPath    = '/srv/mint/finished-images/'
    lockFile        = '/var/run/mint-jobdaemon.pid'
    maxThreads      = (CfgInt, 5)

    def read(self, path, exception = False):
        ConfigFile.read(self, path, exception)
        for arch in cfg.supportedArch:
            if arch not in SUPPORTED_ARCHS:
                log.error("unsupported architecture: %s", arch)
                sys.exit(1)
        if self.serverUrl is None:
            log.error("a server URL must be specified in the config file,"
            " for example:")
            log.error("serverUrl http://username:userpass@"
                      "www.example.com/xmlrpc-private/")
            sys.exit(1)

if __name__ == "__main__":
    parser = OptionParser()
    parser.add_option("-k", "--kill", dest = "kill",
                      action = "store_true",
                      help = "Kill the running ISO generation server.")
    parser.add_option("-c", "--config", dest = "config", default = None,
                      help = "Location of the iso_gen.conf file.")
    parser.add_option("-d", "--debug", dest = "debug", action = "store_true",
                      help = "Enable the debugger on errors.")
    parser.add_option("-n", "--no-daemon", dest = "noDaemon",
                      action = "store_true", default = False,
                      help = "Do not run as a daemon")
    (options, args) = parser.parse_args()

    if options.debug:
        sys.excepthook = util.genExcepthook()
        log.setVerbosity(log.DEBUG)
    else:
        log.setVerbosity(log.INFO)

    # use sys.argv[1] as config file if provided
    # if not, try some standard locations
    cfgFiles = ["iso_gen.conf", None]
    if options.config:
        cfgFile = options.config
    else:
        for cfgFile in cfgFiles:
            if cfgFile:
                if os.access(cfgFile, os.R_OK) and os.path.isfile(cfgFile):
                    break
    if not cfgFile:
        log.error("unable to open iso_gen.conf configuration file."
                  " Please use --config=<path>.")
        sys.exit(1)

    cfg = IsoGenConfig()
    cfg.read(cfgFile)

    # set up the cfg.configPath location so that the image generators
    # know where to look for their configuration files.
    cfg.configPath = os.path.dirname(cfgFile)

    if options.kill:
        kill(cfg.lockFile)
        sys.exit(1)

    if os.access(cfg.lockFile, os.R_OK):
        lock = open(cfg.lockFile, "r")
        pid = lock.read()
        lock.close()
        # check if the pid is actually valid...
        pipeFD = os.popen("ps -p %s -o pid="% pid)
        pidLine = pipeFD.readline()
        pipeFD.close()

        if pid in pidLine:
            log.error("rBuilder ISO generation server already"
                      " running as pid %s", pid)
            sys.exit(1)
        else:
            log.info("Old job daemon pid seems to be invalid. killing.")
            kill(cfg.lockFile)

    log.debug("loading configuration file: %s", cfgFile)
    log.info("using Conary in %s",
             os.path.dirname(sys.modules['conary'].__file__))

    if options.noDaemon:
        sys.excepthook = util.genExcepthook()
        daemon(options, cfg)
    else:
        pid = os.fork()

        if pid == 0:
            # redirect stdout and stderr to job-server.log
            logFile = os.path.join(cfg.logPath, "job-server.log")
            nullf = file("/dev/null", "r+")
            logfd = os.open(logFile, os.O_APPEND | os.O_WRONLY | os.O_CREAT, 0666)
            os.dup2(logfd, sys.stdout.fileno())
            os.dup2(logfd, sys.stderr.fileno())
            os.dup2(nullf.fileno(), sys.stdin.fileno())
            nullf.close()

            pid = os.fork()
            if pid == 0:
                # abandon the controlling tty by resetting session id
                os.setsid()

                sys.stdout.flush()
                sys.stderr.flush()

                daemon(options, cfg)
        else:
            log.info("rBuilder ISO generation server started")
            os._exit(0)
