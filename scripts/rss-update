#!/usr/bin/python
#
# Copyright (c) 2011 rPath, Inc.
#

import logging
import optparse
import os
import sys
import urllib
import urllib2
from conary import conarycfg
from conary.lib import digestlib
from conary.lib.http import opener
from lxml import etree as ET
from lxml.builder import E
from mint import config
from mint import notices_store
from mint.lib import mintutils

log = logging.getLogger('scripts.rss-client')


def main():
    op = optparse.OptionParser()
    op.add_option('-c', '--config', help="Path to the rBuilder config file",
            default=config.RBUILDER_CONFIG)
    op.add_option('-q', '--quiet', action='store_true')

    options, args = op.parse_args()
    if args:
        op.error("Expected no arguments")

    mintutils.setupLogging('/var/log/rbuilder/scripts.log',
            consoleLevel=(options.quiet and logging.ERROR or logging.INFO))

    cfg = config.MintConfig()
    cfg.read(options.config)

    if not cfg.noticesRssFeed:
        log.info("Nothing to do; exiting.")
        return 0

    store = notices_store.createStore(os.path.join(cfg.dataPath, 'notices'),
            cfg.authUser)
    baseUrl = 'https://%s/api/notices/contexts' % cfg.secureHost

    rc = 0
    for url in cfg.noticesRssFeed:
        rc_one = pull(store, url, baseUrl)
        if rc_one:
            rc = rc_one

    return rc


def pull(store, url, baseUrl):
    log.info("Pulling notices from RSS feed %s", url)
    cfg = conarycfg.ConaryConfiguration(True)
    op = opener.URLOpener(proxyMap=cfg.getProxyMap())
    try:
        xmlStream = op.open(url)
    except:
        log.exception("Error fetching notices RSS feed:")
        return 1

    try:
        items = parseFeedStream(xmlStream)
    except:
        log.exception("Error parsing notices RSS feed:")
        return 1

    # First, grab all the available notices (non-logged-in)
    upstreamItems = [x.content for x in store.enumerateStoreGlobal('default')]
    upstreamItems = dict((_hashItem(x), x) for x in upstreamItems)

    for item in items:
        if _hashItem(item, local = True) in upstreamItems:
            continue

        guids = item.findall('guid')
        for guid in guids:
            guid.tag = 'guid-upstream'

        notice = store.storeGlobal('default', '<item/>')
        guid = baseUrl + '/' + notice.id

        item.append(E.guid(guid))
        item.append(E.source(url=baseUrl))
        notice.content = ET.tostring(item,
                xml_declaration=False, encoding='UTF-8')
        store.storeGlobal(None, notice)
        log.info("Added notice %s", guid)

    return 0


def parseFeedStream(xmlStream):
    try:
        xmlDoc = ET.parse(xmlStream)
    except ET.XMLSyntaxError, e:
        raise ParseError("Unable to parse XML file: %s" % str(e))
    xmlRoot = xmlDoc.getroot()
    if xmlRoot.tag != 'rss' or xmlRoot.get('version') != '2.0':
        raise ParseError("XML document is not an RSS 2.0 stream")
    channels = xmlRoot.getchildren()
    if not channels:
        raise ParseError("Channel element not found")
    channel = channels[0]
    items = (x for x in channel.iterchildren() if x.tag == 'item')
    return items


def _hashItem(item, local = False):
    """
    Generate some kind of unique identifier for this item.
    If local is False, the unique ID is generated out of the guid nodes,
    otherwise we use guid-upstream nodes.
    """
    # Make a copy of the item first
    if not isinstance(item, str):
        item = ET.tostring(item)
    elem = ET.fromstring(item)
    guids = elem.findall('guid')
    if not local:
        for guid in guids:
            elem.remove(guid)
        guids = elem.findall('guid-upstream')
    if guids:
        guids = [ x.text for x in guids ]
        return ''.join(sorted(guids))
    # No guid-upstream; hash the node
    return digestlib.sha1(ET.tostring(elem)).hexdigest()

    def getStream(self, streamName):
        if not streamName.startswith("http"):
            try:
                xmlStream = file(streamName)
            except IOError, e:
                raise StreamOpenError("Unable to open XML file: %s" % str(e))
            return xmlStream

        req = urllib2.Request(streamName)
        ret = self.opener.open(req)
        if ret.code != 200:
            raise StreamOpenError("Unable to open XML stream %s" % streamName)
        return ret


class ParseError(RuntimeError):
    pass


class StreamOpenError(RuntimeError):
    pass


if __name__ == '__main__':
    sys.exit(main())
